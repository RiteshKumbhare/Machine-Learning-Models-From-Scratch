{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0,1]\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Flatten images: (28, 28) â†’ (784,)\n",
        "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "# Add bias term: Append a column of ones (Now shape: (N, 785))\n",
        "x_train_bias = np.hstack([x_train_flat[:2000], np.ones((2000, 1))])\n",
        "x_test_bias = np.hstack([x_test_flat[:500], np.ones((500, 1))])\n",
        "\n",
        "# Select corresponding labels & reshape to column vectors\n",
        "y_train_sampled = y_train[:2000].reshape(-1, 1)\n",
        "y_test_sampled = y_test[:500].reshape(-1, 1)\n",
        "\n",
        "# Print final dataset shapes\n",
        "print(f\"Training set: {x_train_bias.shape}, Labels: {y_train_sampled.shape}\")\n",
        "print(f\"Test set: {x_test_bias.shape}, Labels: {y_test_sampled.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieVlOa1OVSE4",
        "outputId": "8a3e0b7f-8721-48ab-f72f-dcd1a588287a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (2000, 785), Labels: (2000, 1)\n",
            "Test set: (500, 785), Labels: (500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = np.random.randn(785, 10) * 0.001\n",
        "num_classes = W.shape[1]"
      ],
      "metadata": {
        "id": "B7hvhK3xVSsl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_linear_unvectorized(X, y, W, reg):\n",
        "  num_train = X.shape[0]\n",
        "  num_classes = W.shape[1]\n",
        "  loss = 0.0\n",
        "  dW = np.zeros_like(W)\n",
        "\n",
        "  for i in range(num_train):\n",
        "    scores = np.dot(X[i], W)\n",
        "    scores -= np.max(scores)\n",
        "    exp_scores = np.exp(scores)\n",
        "    softmax_probs = exp_scores / np.sum(exp_scores)\n",
        "    loss += -np.log(softmax_probs[y[i]])\n",
        "\n",
        "    for j in range(num_classes):\n",
        "      if j == y[i]:\n",
        "        dW[:, j] += (softmax_probs[j] - 1) * X[i]\n",
        "      else:\n",
        "        dW[:, j] += softmax_probs[j] * X[i]\n",
        "\n",
        "  loss /= num_train\n",
        "  dW /= num_train\n",
        "\n",
        "  loss += reg * np.sum(W * W)\n",
        "  dW += 2 * reg * W\n",
        "\n",
        "  return loss, dW"
      ],
      "metadata": {
        "id": "UWu3AvXmVr6N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_train_unvectorized(X, y, W, reg, alpha=0.01, iters=100):\n",
        "  num_train = X.shape[0]\n",
        "  for i in range(iters):\n",
        "    loss, dW = softmax_linear_unvectorized(X, y, W, reg)\n",
        "    W -= alpha * dW\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      print(f\"Epoch {i}: Loss = {float(loss):.4f}\")\n",
        "  return W"
      ],
      "metadata": {
        "id": "su_WsszHXssP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = softmax_train_unvectorized(x_train_bias, y_train_sampled, W, reg=0.0001, alpha=0.01, iters=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLltR3GdajBC",
        "outputId": "3e1c1478-b2ef-4ede-c187-5ebfa98fbfcb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-1982ba5dc22f>:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(f\"Epoch {i}: Loss = {float(loss):.4f}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 2.2917\n",
            "Epoch 10: Loss = 2.1863\n",
            "Epoch 20: Loss = 2.0887\n",
            "Epoch 30: Loss = 1.9983\n",
            "Epoch 40: Loss = 1.9144\n",
            "Epoch 50: Loss = 1.8366\n",
            "Epoch 60: Loss = 1.7645\n",
            "Epoch 70: Loss = 1.6977\n",
            "Epoch 80: Loss = 1.6359\n",
            "Epoch 90: Loss = 1.5786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.dot(x_test_bias, W)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "accuracy = np.mean(y_pred == y_test_sampled)"
      ],
      "metadata": {
        "id": "ZS1qxA6Nammm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6kOm0sMbl5g",
        "outputId": "619384b9-c8e2-412d-f849-96c02943d7d9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.102612)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U81c5yTUboaP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}